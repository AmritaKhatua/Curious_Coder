{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "usual-commonwealth",
   "metadata": {},
   "source": [
    "### Decision Trees as Regression Models - California Housing~ Precticting House Price based on HouseAge,Room# and geographiocal location\n",
    "\n",
    "We use the California Housing dataset to obtain a Decision Tree model, which is then used to predict the median house prices in various districts across California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Import the tools you’ll need\n",
    "# These are fundamental libraries:\n",
    "#\n",
    "# numpy (np): fast numerical arrays and math operations.\n",
    "# pandas (pd): for working with tables (dataframes).\n",
    "# random (rnd): a tiny helper if you need simple randomness.\n",
    "#\n",
    "# Why it matters — even simple data science projects start\n",
    "# by importing these building blocks.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Make Jupyter show every output in a cell - this is optional , I added as I like tio see what each line does \n",
    "# Jupyter normally shows only the last expression’s output in a cell.\n",
    "# This line configures the notebook so that every expression’s result in a cell is displayed.\n",
    "#\n",
    "# Why it matters — great for teaching and debugging because you can see\n",
    "# intermediate outputs (dataframes, numbers, etc.) without adding print() everywhere.\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1dc4e4-1560-400c-9404-61c76c05f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Load the California Housing dataset into a DataFrame\n",
    "#\n",
    "# What this does —\n",
    "# scikit-learn provides the California housing dataset.\n",
    "# We load it and wrap the features into a pandas.DataFrame with readable column names.\n",
    "# Displaying cali_df shows the table.\n",
    "#\n",
    "# Why it matters —\n",
    "# DataFrames make it easy to inspect columns and values,\n",
    "# which is the first step in any data project.\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "cali_dataset=fetch_california_housing()\n",
    "cali_df = pd.DataFrame(cali_dataset.data,columns=cali_dataset.feature_names)\n",
    "cali_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f540d0-0dba-4ac1-a707-247dc7390ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Add the target variable (median house value)\n",
    "#\n",
    "# What this does —\n",
    "# The dataset separates features and targets; here we add the target\n",
    "# (median house value for each row) as a new column named 'MedHouseVal'.\n",
    "#\n",
    "# Why it matters —\n",
    "# Now the DataFrame has both the input features and\n",
    "# the value we want to predict (the target).\n",
    "\n",
    "cali_df['MedHouseVal']=cali_dataset.target\n",
    "cali_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082848fe-3350-4d13-ab8d-e8ec09d0028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Document the data (comments)\n",
    "# Data Sorce Link :https://scikit-learn.org/0.24/datasets/real_world.html#california-housing-dataset\n",
    "# Attribute Information\n",
    "# MedInc median income in block\n",
    "# HouseAge median house age in block\n",
    "# AveRooms average number of rooms\n",
    "# AveBedrms average number of bedrooms\n",
    "# Population block population\n",
    "# AveOccup average house occupancy\n",
    "# Latitude house block latitude\n",
    "# Longitude house block longitude\n",
    "\n",
    "names=cali_dataset.feature_names\n",
    "names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb2929-1c95-4295-b7a4-6b5f29e21002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) (Typical) Quick EDA — inspect head, info, shape, describe\n",
    "#\n",
    "# What this does —\n",
    "# Shows the first few rows, data types, summary statistics,\n",
    "# and the number of rows and columns.\n",
    "#\n",
    "# Why it matters —\n",
    "# Quick checks help catch missing values, unexpected data types,\n",
    "# or obvious data issues before moving on to modeling.\n",
    "\n",
    "cali_df.head()\n",
    "cali_df.info()\n",
    "cali_df.describe()\n",
    "cali_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Prepare features and target for modeling\n",
    "#\n",
    "# What this does —\n",
    "# X contains the input features; y contains the target values.\n",
    "# We separate them because scikit-learn models expect this format.\n",
    "#\n",
    "# Why it matters —\n",
    "# Modeling functions require a feature matrix (X) and a label vector (y).\n",
    "\n",
    "X = cali_df.drop('MedHouseVal', axis=1)\n",
    "y = cali_df['MedHouseVal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa114a2-3fde-4233-b462-49d785073491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Prepare features and target for modeling using DecisionTreeRegressor from sklearn\n",
    "#\n",
    "# What this does —\n",
    "# X contains the input features ( 8 input colums); y contains the target values(new predicted column).\n",
    "# We separate them because scikit-learn models expect this format.\n",
    "#\n",
    "# Why it matters —\n",
    "# Modeling functions require a feature matrix (X) and a label vector (y).\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "array= cali_df.values\n",
    "\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "\n",
    "X\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Split into training and test sets\n",
    "#\n",
    "# What this does —\n",
    "# Randomly splits the data into a training set (used to train the model)\n",
    "# and a test set (used to evaluate it).\n",
    "# test_size=0.2 reserves 20% of the data for testing.\n",
    "# random_state ensures the split is reproducible.\n",
    "#\n",
    "# Why it matters —\n",
    "# Testing on unseen data gives a realistic sense of how well\n",
    "# the model will perform on new, unseen inputs.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1234)\n",
    "len(X_train)\n",
    "len(Y_train)\n",
    "len(X_test)\n",
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-wrist",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "<u>Note</u>: Changing max_leaf_nodes from 10 to 20 only results in an R-squared increase\n",
    "of 0.04, and a far greater increase in depth/complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae7ce6-30d9-4efd-b69a-f0a7e4d925f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Fit a Decision Tree Regressor\n",
    "#\n",
    "# What this does —\n",
    "# Creates a Decision Tree regression model and trains (fits) it\n",
    "# using the training data (X_train, y_train).\n",
    "#\n",
    "# Why it matters —\n",
    "# Decision Trees are easy to visualize and understand.\n",
    "# They’re great for teaching regression intuition and\n",
    "# for seeing how the model makes decisions based on feature values.\n",
    "\n",
    "model=DecisionTreeRegressor(max_leaf_nodes = 10)\n",
    "regTree=model.fit(X_train,Y_train)\n",
    "regTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2da938-856d-40ab-9b4b-a29251bc35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 10: Making a prediction for a random sample\n",
    "# What this does:\n",
    "# rnd.seed(123458) — sets a random seed.\n",
    "# This ensures that every time you run the notebook, \n",
    "# it picks the same random number. (Reproducibility = good science!)\n",
    "#\n",
    "# rnd.randrange(X.shape[0]) — chooses a random integer between 0 \n",
    "# and the total number of rows in X.\n",
    "#\n",
    "# X_new = X_new.reshape(1,8) — selects one random row (a single data point) from the dataset.\n",
    "# Displaying X_new shows its feature values — e.g., median income, house age, etc.\n",
    "#\n",
    "# Why this matters:\n",
    "# Instead of predicting on the whole test set, this picks one house and asks the model,\n",
    "# “What price do you think this house will have?”\n",
    "\n",
    "rnd.seed(123458)\n",
    "X_new=X[rnd.randrange(X.shape[0])]\n",
    "X_new\n",
    "\n",
    "X_new=X_new.reshape(1,8)\n",
    "X_new\n",
    "YHat=model.predict(X_new)\n",
    "YHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1b2d6-7886-4140-9bf7-3a9541c2b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Presenting the prediction in a clean table\n",
    "\n",
    "# Creates a small table (DataFrame) from your one data sample.\n",
    "# Each column has its proper name (like MedInc, HouseAge, etc.).\n",
    "# Adds a new column called \"Predicted Price,\" which stores your model’s output\n",
    "# df.head(1) Shows the first (and only) row — all the house details plus the model’s predicted price.\n",
    "\n",
    "df=pd.DataFrame(X_new,columns = names)\n",
    "df[\"Predicted Price\"]=YHat\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def8a66a-b4eb-4afd-a2d7-4a1f3fe73417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12 Predict & evaluate the model\n",
    "#\n",
    "# What this does —\n",
    "\n",
    "# imports the R² (R-squared) metric function from scikit-learn.\n",
    "# R² is a standard way to measure the performance of regression models \n",
    "# (like your DecisionTreeRegressor).\n",
    "#\n",
    "# Interpretation of R²:\n",
    "# R² = 1 → Perfect prediction (the model explains 100% of the variation in the target).\n",
    "# R² = 0 → The model is no better than predicting the mean (no explanatory power).\n",
    "# R² < 0 → The model performs worse than a simple average guess.\n",
    "#\n",
    "# The predict() method applies the trained Decision Tree model\n",
    "# to unseen test data (X_test) to generate predictions (y_Hat).\n",
    "\n",
    "# Here, you use your trained model to predict outputs (YHat) for the test input data (X_test).\n",
    "# The result, YHat, is an array of predicted values — e.g., predicted house prices.\n",
    "# Why it matters —\n",
    "# These metrics tell you whether the model is accurate enough to be useful\n",
    "# or if it needs improvement (through tuning, more data, or a different model).\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "YHat=model.predict(X_test)\n",
    "r2 = r2_score(Y_test, YHat)\n",
    "print(\"R-Squared = \", np.round(r2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image   # To display images directly inside Jupyter Notebook\n",
    "from sklearn import tree            # To access decision tree functions from scikit-learn\n",
    "import matplotlib.image as mpimg     # To read and display image files using matplotlib\n",
    "import io                            # To handle in-memory file-like objects (used for .dot data)\n",
    "import matplotlib.pyplot as plt      # To create and show plots or images\n",
    "!pip install pydotplus               # Install pydotplus library for converting .dot files to images\n",
    "import pydotplus                     # Import pydotplus to create image graphs from .dot data\n",
    "!pip install graphviz                # Install Graphviz backend to render decision tree visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1099d3a1-4d56-4d6c-a098-83f1426077fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = io.StringIO()   # Create an in-memory text stream to store the decision tree data in .dot format\n",
    "dot_data                   # Display the empty StringIO object (optional, just shows it's created)\n",
    "\n",
    "tree.export_graphviz(regTree, out_file=dot_data, filled=True, feature_names=names)  \n",
    "# Export the trained decision tree (regTree) as .dot data with filled color nodes and feature names\n",
    "\n",
    "# Draw graph\n",
    "pydotplus.graph_from_dot_data(dot_data.getvalue()).write_png('dt.png')  \n",
    "# Convert the .dot data to a graph object and save it as a PNG image file (dt.png)\n",
    "\n",
    "plt.figure(figsize=(100, 100))  \n",
    "# Create a very large figure to properly display the detailed decision tree image\n",
    "\n",
    "img = mpimg.imread('dt.png')  \n",
    "# Read the saved PNG image file into Python using matplotlib\n",
    "\n",
    "implot = plt.imshow(img)  \n",
    "# Display the image of the decision tree inside the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc800cab-55b0-42c5-b972-3c98a0f92cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to read the tree (in simple words):\n",
    "#Start at the top (root node) — here the model first checks MedInc (median income).\n",
    "#Follow the True/False branches depending on the condition.\n",
    "#Keep following until you reach a leaf node (no further splits).\n",
    "#The “value” at the leaf is your model’s predicted target for that path.\n",
    "\n",
    "# Attribute        Meaning\n",
    "# ------------------------------------------------------------\n",
    "# Feature ≤ Threshold   # Splitting rule for that node\n",
    "# squared_error         # How “impure” or variable the node’s values are\n",
    "# samples               # Number of data points in that node\n",
    "# value                 # Predicted output (mean target value) for that node\n",
    "# Color                 # Indicates relative prediction value (light = low, dark = high)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-garlic",
   "metadata": {},
   "source": [
    "### Examine the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_df.shape   # Returns the number of rows and columns in the DataFrame (as a tuple)\n",
    "regTree.max_features_   # Shows the number of features considered when looking for the best split in the trained Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame showing each feature name and its importance score from the trained decision tree\n",
    "feature_imp = pd.DataFrame({\"Feature\": cali_dataset.feature_names,\n",
    "                           \"Importance\": regTree.feature_importances_})\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_features = feature_imp[feature_imp[\"Importance\"] > 0] # Filter out only the features that have non-zero importance in the model\n",
    "relevant_features = relevant_features.sort_values([\"Importance\"]) # Sort the remaining features in ascending order of their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns   # Import Seaborn library for creating attractive and easy-to-read plots\n",
    "sns.barplot(x=\"Feature\", y=\"Importance\", data=relevant_features)  \n",
    "# Plot a bar chart showing each feature on the x-axis and its importance score on the y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-street",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
